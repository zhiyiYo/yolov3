# coding:utf-8
import time
import traceback
from pathlib import Path
from datetime import datetime

import torch
from torch import optim, cuda
from torch.backends import cudnn
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
from utils.log_utils import LossLogger
from utils.datetime_utils import time_delta

from .dataset import collate_fn
from .loss import YoloLoss
from .yolo import Yolo


def exception_handler(train_func):
    """ å¤„ç†è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿçš„å¼‚å¸¸å¹¶ä¿å­˜æ¨¡åž‹ """
    def wrapper(train_pipeline, *args, **kwargs):
        try:
            return train_func(train_pipeline, *args, **kwargs)
        except BaseException as e:
            if not isinstance(e, KeyboardInterrupt):
                traceback.print_exc()

            train_pipeline.save()

            # æ¸…ç©º GPU ç¼“å­˜
            cuda.empty_cache()

            exit()

    return wrapper


class TrainPipeline:
    """ è®­ç»ƒæ¨¡åž‹æµæ°´çº¿ """

    def __init__(self, n_classes: int, image_size: int, anchors: list, dataset: Dataset, darknet_path: str = None,
                 yolo_path: str = None, lr=0.01, backbone_lr=1e-3, momentum=0.9, weight_decay=4e-5, lr_step_size=20,
                 batch_size=16, start_epoch=0, max_epoch=60, save_frequency=5, use_gpu=True, save_dir='model',
                 log_file: str = None, log_dir='log'):
        """
        Parameters
        ----------
        n_classes: int
            ç±»åˆ«æ•°

        image_size: int
            è¾“å…¥ Yolo ç¥žç»ç½‘ç»œçš„å›¾ç‰‡å¤§å°

        anchors: list of shape `(3, n_anchors, 2)`
            è¾“å…¥ç¥žç»ç½‘ç»œçš„å›¾ç‰‡å°ºå¯¸ä¸º 416 æ—¶çš„å…ˆéªŒæ¡†å°ºå¯¸

        dataset: Dataset
            è®­ç»ƒæ•°æ®é›†

        darknet_path: str
            é¢„è®­ç»ƒçš„ darknet53 æ¨¡åž‹æ–‡ä»¶è·¯å¾„

        yolo_path: Union[str, None]
            Yolo æ¨¡åž‹æ–‡ä»¶è·¯å¾„ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§é€‰æ‹©:
            * å¦‚æžœä¸ä¸º `None`ï¼Œå°†ä½¿ç”¨æ¨¡åž‹æ–‡ä»¶ä¸­çš„å‚æ•°åˆå§‹åŒ– `Yolo`
            * å¦‚æžœä¸º `None`ï¼Œå°†éšæœºåˆå§‹åŒ– darknet53 ä¹‹åŽçš„å„å±‚å‚æ•°

        lr: float
            å­¦ä¹ çŽ‡

        backbone_lr: float
            ä¸»å¹²ç½‘ç»œå­¦ä¹ çŽ‡

        momentum: float
            å†²é‡

        weight_decay: float
            æƒé‡è¡°å‡

        lr_step_size: int
            å­¦ä¹ çŽ‡é€€ç«çš„æ­¥é•¿

        batch_size: int
            è®­ç»ƒé›† batch å¤§å°

        start_epoch: int
            Yolo æ¨¡åž‹æ–‡ä»¶åŒ…å«çš„å‚æ•°æ˜¯è®­ç»ƒäº†å¤šå°‘ä¸ª epoch çš„ç»“æžœ

        max_epoch: int
            æœ€å¤šè¿­ä»£å¤šå°‘ä¸ª epoch

        save_frequency: int
            è¿­ä»£å¤šå°‘ä¸ª epoch ä¿å­˜ä¸€æ¬¡æ¨¡åž‹

        use_gpu: bool
            æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿè®­ç»ƒ

        save_dir: str
            ä¿å­˜ SSD æ¨¡åž‹çš„æ–‡ä»¶å¤¹

        log_file: str
            è®­ç»ƒæŸå¤±æ•°æ®åŽ†å²è®°å½•æ–‡ä»¶ï¼Œè¦æ±‚æ˜¯ json æ–‡ä»¶

        save_dir: str
            è®­ç»ƒæŸå¤±æ•°æ®ä¿å­˜çš„æ–‡ä»¶å¤¹
        """
        self.dataset = dataset
        self.save_dir = Path(save_dir)
        self.use_gpu = use_gpu
        self.save_frequency = save_frequency
        self.batch_size = batch_size

        self.max_epoch = max_epoch
        self.start_epoch = start_epoch
        self.current_epoch = start_epoch

        if use_gpu and cuda.is_available():
            self.device = torch.device('cuda')
            cudnn.benchmark = True
        else:
            self.device = torch.device('cpu')

        # åˆ›å»ºæ¨¡åž‹
        self.model = Yolo(n_classes, image_size, anchors).to(self.device)
        if yolo_path:
            self.model.load(yolo_path)
            print('ðŸ§ª æˆåŠŸè½½å…¥ Yolo æ¨¡åž‹ï¼š' + yolo_path)
        elif darknet_path:
            self.model.darknet.load(darknet_path)
            print('ðŸ§ª æˆåŠŸè½½å…¥ Darknet53 æ¨¡åž‹ï¼š' + darknet_path)
        else:
            raise ValueError("å¿…é¡»æŒ‡å®šé¢„è®­ç»ƒçš„ Darknet53 æ¨¡åž‹æ–‡ä»¶è·¯å¾„")

        # åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        self.criterion = YoloLoss(anchors, n_classes, image_size)

        darknet_params = self.model.darknet.parameters()
        other_params = [i for i in self.model.parameters()
                        if i not in darknet_params]
        self.optimizer = optim.SGD(
            [
                {"params": darknet_params, 'initial_lr': backbone_lr, 'lr': backbone_lr},
                {'params': other_params, 'initial_lr': lr, 'lr': lr}
            ],
            momentum=momentum,
            weight_decay=weight_decay
        )

        self.lr_schedule = optim.lr_scheduler.StepLR(
            self.optimizer, lr_step_size, 0.1, last_epoch=start_epoch)

        # è®­ç»ƒæŸå¤±è®°å½•å™¨
        self.n_batches = len(self.dataset)//self.batch_size
        self.logger = LossLogger(self.n_batches, log_file, log_dir)

    def save(self):
        """ ä¿å­˜æ¨¡åž‹å’Œè®­ç»ƒæŸå¤±æ•°æ® """
        self.pbar.close()
        self.save_dir.mkdir(exist_ok=True, parents=True)

        # ä¿å­˜æ¨¡åž‹
        self.model.eval()
        path = self.save_dir/f'Yolo_{self.current_epoch+1}.pth'
        torch.save(self.model.state_dict(), path)

        # ä¿å­˜è®­ç»ƒæŸå¤±æ•°æ®
        self.logger.save(f'train_losses_{self.current_epoch+1}')

        print(f'\nðŸŽ‰ å·²å°†å½“å‰æ¨¡åž‹ä¿å­˜åˆ° {path.absolute()}\n')

    @exception_handler
    def train(self):
        """ è®­ç»ƒæ¨¡åž‹ """
        t = time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime(time.time()))
        self.save_dir = self.save_dir/t
        self.logger.save_dir = self.logger.save_dir/t

        # æ•°æ®è¿­ä»£å™¨
        data_loader = DataLoader(
            self.dataset, self.batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn)

        bar_format = '{desc}{n_fmt:>4s}/{total_fmt:<4s}|{bar}|{postfix}'
        print('ðŸš€ å¼€å§‹è®­ç»ƒï¼')

        for e in range(self.start_epoch, self.max_epoch):
            self.current_epoch = e

            self.model.train()

            # åˆ›å»ºè¿›åº¦æ¡
            self.pbar = tqdm(total=self.n_batches, bar_format=bar_format)
            self.pbar.set_description(f"\33[36mðŸ’« Epoch {(e+1):5d}")
            start_time = datetime.now()

            for images, targets in data_loader:
                # é¢„æµ‹è¾¹ç•Œæ¡†ã€ç½®ä¿¡åº¦å’Œæ¡ä»¶ç±»åˆ«æ¦‚çŽ‡
                preds = self.model(images.to(self.device))

                # è¯¯å·®åå‘ä¼ æ’­
                self.optimizer.zero_grad()
                loc_loss, conf_loss, cls_loss = self.criterion(preds, targets)
                loss = loc_loss + conf_loss + cls_loss
                loss.backward()
                self.optimizer.step()

                # è®°å½•è¯¯å·®
                self.logger.update(
                    loc_loss.item(), conf_loss.item(), cls_loss.item())

                # æ›´æ–°è¿›åº¦æ¡
                cost_time = time_delta(start_time)
                self.pbar.set_postfix_str(
                    f'loss: {loss.item():.5f}, loc_loss: {loc_loss.item():.5f}, conf_loss: {conf_loss.item():.5f}, cls_loss: {cls_loss.item():.5f}, æ‰§è¡Œæ—¶é—´: {cost_time}\33[0m')
                self.pbar.update()

            # å…³é—­è¿›åº¦æ¡
            self.pbar.close()

            # å­¦ä¹ çŽ‡é€€ç«
            self.lr_schedule.step()

            # å®šæœŸä¿å­˜æ¨¡åž‹
            if e > self.start_epoch and (e+1-self.start_epoch) % self.save_frequency == 0:
                self.save()

        self.save()
